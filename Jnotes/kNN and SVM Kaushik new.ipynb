{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74ebf67",
   "metadata": {},
   "source": [
    "# CLASSICAL APPROACHES "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb35cbb",
   "metadata": {},
   "source": [
    "1. Import pandas and numpy libraries.\n",
    "2. Read the dataset csv file into a pandas Dataframe.\n",
    "3. Split the dataset per subject and read them into two separate dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ec765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataframe = pd.read_csv('..\\sensor_data\\Dataset.csv')\n",
    "dataframe = dataframe[['E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'A1', 'A2', 'A3', 'W1', 'W2', 'W3', 'Subject', 'Label']]\n",
    "dataframe = dataframe.fillna('null')\n",
    "df_subj1 = dataframe.loc[dataframe['Subject'] == 'Subject1']\n",
    "df_subj2 = dataframe.loc[dataframe['Subject'] == 'Subject2']\n",
    "new_df_subj2 = df_subj2.loc[df_subj2['Label'] != 'dribbling']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e29e949",
   "metadata": {},
   "source": [
    "Descriptive Statistics (Overview of the Databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74644374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataframe[\"Label\"].hist(bins=15)\n",
    "plt.show()\n",
    "\n",
    "df_subj1[\"Label\"].hist(bins=15)\n",
    "plt.show()\n",
    "\n",
    "df_subj2[\"Label\"].hist(bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f6867",
   "metadata": {},
   "source": [
    "Define Sliding window method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942db86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_samples(data, samples_per_window, overlap_ratio):\n",
    "    windows = []\n",
    "    indices = []\n",
    "    curr =  0\n",
    "    win_len = samples_per_window\n",
    "    if overlap_ratio !=  None :\n",
    "        overlapping_elements = int((overlap_ratio / 100) * (win_len))\n",
    "    if overlapping_elements >= win_len:\n",
    "        print('Number of overlapping elements exceeds window size.')\n",
    "    while (curr < len(data) - win_len):\n",
    "         windows.append(data[curr:curr + win_len])\n",
    "         indices.append([curr, curr + win_len])\n",
    "         curr = curr + win_len - overlapping_elements\n",
    "         \n",
    "         try:\n",
    "            result_windows = np.array(windows)\n",
    "            result_indices = np.array(indices)\n",
    "         except:\n",
    "             result_windows = np.empty( shape =(len(windows), win_len, data.shape[1]), dtype =object)\n",
    "             result_indices = np.array(indices)\n",
    "             for i in range(0, len(windows)):\n",
    "                result_windows[i] = windows[i]\n",
    "                result_indices[i] = indices[i]\n",
    "    return result_windows, result_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a10470",
   "metadata": {},
   "source": [
    "1. Import kNN classifier and train the model\n",
    "2. Check Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a37c106",
   "metadata": {},
   "source": [
    "1. Import SVM classifier and train the model\n",
    "2. Check Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ca2f6",
   "metadata": {},
   "source": [
    "Per subject validation using Sliding window\n",
    "1. Set test subject as required\n",
    "2. Remove unnecessary Columns\n",
    "3. Converting string labels into numbers using labelencoder\n",
    "4. Apply sliding window and then split data into train and test sets\n",
    "5. Reshape the train and test matrices to match with the algorithm input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_subject_SL(dataframe):\n",
    "    X = dataframe.drop(\"Label\", axis=1)\n",
    "    X = X.drop(\"Subject\", axis=1)\n",
    "    y = dataframe[\"Label\"]\n",
    "\n",
    "    # Import LabelEncoder\n",
    "    from sklearn import preprocessing\n",
    "    #creating labelEncoder\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # Converting string labels into numbers.\n",
    "    y_encoded=le.fit_transform(y)\n",
    "\n",
    "    X_windows, X_indices = sliding_window_samples(X, 100, 70)\n",
    "    y_windows, y_indices = sliding_window_samples(y_encoded, 100, 70)\n",
    "        \n",
    "    X_windows = np.reshape(X_windows, (X_windows.shape[0], -1))\n",
    "    from scipy import stats\n",
    "    y_windows = (stats.mode(y_windows, axis=1)).mode\n",
    "    y_windows = np.reshape(y_windows, (y_windows.shape[0],))\n",
    "    \n",
    "    #Import kNN model\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    #Create a kNN Classifier\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    print(\"kNN\")\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\", (cross_val_score(model, X_windows, y_windows, cv=10).mean()))\n",
    "    # Model f1_score: weighted average of the precision and recall\n",
    "    print(\"f1_score:\", (cross_val_score(model, X_windows, y_windows, cv=10, scoring='f1_macro').mean()))\n",
    "    \n",
    "    #Import svm model\n",
    "    from sklearn import svm\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(kernel='rbf', C=1, gamma='auto', random_state=42)\n",
    "    \n",
    "    print(\"SVM\")\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\", (cross_val_score(clf, X_windows, y_windows, cv=10).mean()))\n",
    "    # Model f1_score: weighted average of the precision and recall\n",
    "    print(\"f1_score:\", (cross_val_score(clf, X_windows, y_windows, cv=10, scoring='f1_macro').mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cffa532",
   "metadata": {},
   "source": [
    "Cross subject validation using Sliding window\n",
    "1. Remove data with label 'dribbling' for subject2\n",
    "2. Select train and test subjects as required\n",
    "3. Remove unnecessary Columns\n",
    "4. Converting string labels into numbers using labelencoder\n",
    "5. Apply sliding window on the train and test sets \n",
    "6. Reshape the train and test matrices to match with the algorithm input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_subject_SL(train_data, test_data):\n",
    "    X_train = train_data.drop(\"Label\", axis=1)\n",
    "    X_train = X_train.drop(\"Subject\", axis=1)\n",
    "    y_train = train_data[\"Label\"]\n",
    "\n",
    "    X_test = test_data.drop(\"Label\", axis=1)\n",
    "    X_test = X_test.drop(\"Subject\", axis=1)\n",
    "    y_test = test_data[\"Label\"]\n",
    "\n",
    "    # Import LabelEncoder\n",
    "    from sklearn import preprocessing\n",
    "    #creating labelEncoder\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # Converting string labels into numbers.\n",
    "    y_train=le.fit_transform(y_train)\n",
    "    y_test=le.fit_transform(y_test)\n",
    "\n",
    "    X_train, X_indices_train = sliding_window_samples(X_train, 100, 70)\n",
    "    y_train, y_indices_train = sliding_window_samples(y_train, 100, 70)\n",
    "    X_test, X_indices_test = sliding_window_samples(X_test, 100, 70)\n",
    "    y_test, y_indices_test = sliding_window_samples(y_test, 100, 70)\n",
    "    \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "    from scipy import stats\n",
    "    y_train = (stats.mode(y_train, axis=1)).mode\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0],))\n",
    "    y_test = (stats.mode(y_test, axis=1)).mode\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0],))\n",
    "\n",
    "   #Import kNN model\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    #Create a kNN Classifier\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    #Train the model using the training sets    \n",
    "    model.fit(X_train,y_train)\n",
    "    #Predict Output\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    from sklearn import metrics\n",
    "    print(\"kNN\")\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    # Model f1_score: weighted average of the precision and recall\n",
    "    print(\"f1_score:\", metrics.f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    #Import svm model\n",
    "    from sklearn import svm\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(kernel='rbf', C=1, gamma='auto', random_state=42)\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    from sklearn import metrics\n",
    "    print(\"SVM\")\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    # Model f1_score: weighted average of the precision and recall\n",
    "    print(\"f1_score:\", metrics.f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05250654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal and Per subject validations\n",
    "print(\"OverallDataset:\")\n",
    "per_subject_SL(dataframe) # Overall dataset\n",
    "\n",
    "print(\"Subject1:\") \n",
    "per_subject_SL(df_subj1) # Subject 1\n",
    "\n",
    "print(\"Subject2:\")\n",
    "per_subject_SL(df_subj2) # Subject 2\n",
    "\n",
    "# Cross subject validations\n",
    "print(\"Subject1:Train, Subject2:Test\") \n",
    "cross_subject_SL(df_subj1, new_df_subj2) # Subject1:Train\n",
    "\n",
    "print(\"Subject2:Train, Subject1:Test\")\n",
    "cross_subject_SL(new_df_subj2, df_subj1) # Subject2:Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6acd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964b2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
